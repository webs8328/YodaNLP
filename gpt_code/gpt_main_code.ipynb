{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8db780e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16d920f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "def fine_tune_gpt2(model_name, train_file, output_dir):\n",
    "    # Load GPT-2 model and tokenizer\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "    config = LoraConfig(\n",
    "        r=32,\n",
    "        lora_alpha=32,\n",
    "        target_modules=[\"c_proj\"],\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"lora_only\",\n",
    "        modules_to_save=[\"decode_head\"],\n",
    "    )\n",
    "    lora_model = get_peft_model(model, config)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load training dataset\n",
    "    train_dataset = TextDataset(\n",
    "        tokenizer=tokenizer,\n",
    "        file_path=train_file,\n",
    "        block_size=128)\n",
    "    # Create data collator for language modeling\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "    # Set training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=1,\n",
    "        per_device_train_batch_size=4,\n",
    "        save_steps=500,\n",
    "    )\n",
    "    # Train the model\n",
    "    trainer = Trainer(\n",
    "        model=lora_model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=train_dataset,\n",
    "        tokenizer= tokenizer\n",
    "    )\n",
    "    trainer.train()\n",
    "    # Save the fine-tuned model\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99275dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6bc2f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6646cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_funcs' from '/home/webs8328/cs182_proj/gpt_code/../data/data_funcs.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../data')\n",
    "\n",
    "import data_funcs as df\n",
    "import importlib\n",
    "importlib.reload(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ec70775",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = df.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f153df7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['source', 'term', 'quantifier_frequency', 'quantifier_number', 'generic_sentence', 'score'],\n",
      "    num_rows: 3433000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc2c4fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['User: Tell me about a.net income.\\nYoda: By net sales, a.net income is divided. ',\n",
       " 'User: Tell me about a.sound wave.\\nYoda: Reflect, a.sound waves can. ',\n",
       " 'User: Tell me about a.this chapter.\\nYoda: With some wonderful images, a.this chapter begins. ']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.format_data_yoda(ds, [1, 3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "866c9111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name <class 'inspect._empty'> <class 'inspect._empty'> POSITIONAL_ONLY\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "signature = inspect.signature(ds.__getattribute__).parameters\n",
    "for name, parameter in signature.items():\n",
    "    print(name, parameter.default, parameter.annotation, parameter.kind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "034ea8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset\n"
     ]
    }
   ],
   "source": [
    "print(str(ds_test.__class__.__name__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c29bcfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Tell me about a.net income.\n",
      "Yoda: By net sales, a.net income is divided. \n",
      "User: Tell me about a.p.e motorcycle.\n",
      "Yoda: In bondage videos, a.p.e motorcycle babes specializes. \n",
      "User: Tell me about aba.\n",
      "Yoda: On data to make decisions about behavior, aba relies. \n",
      "User: Tell me about a.sound wave.\n",
      "Yoda: Reflect, a.sound waves can. \n",
      "User: Tell me about a.p.e motorcycle.\n",
      "Yoda: In bondage videos, a.p.e motorcycle babes specializes. \n",
      "User: Tell me about action.\n",
      "Yoda: Into account immediately, every action is taken. \n",
      "User: Tell me about a.this chapter.\n",
      "Yoda: With some wonderful images, a.this chapter begins. \n",
      "User: Tell me about a.their image.\n",
      "Yoda: A.their images are inverted. \n",
      "User: Tell me about a.p.e motorcycle.\n",
      "Yoda: In bondage videos, a.p.e motorcycle babes specializes. \n",
      "User: Tell me about actual fishing.\n",
      "Yoda: After class, actual fishing is encouraged. \n",
      "User: Tell me about abiotic factor.\n",
      "Yoda: A physical or nonliving factor that shapes an ecosystem, abiotic factor is. \n"
     ]
    }
   ],
   "source": [
    "for i in df.format_data_yoda(ds, [1, 2, 434,3, 2,23000, 5, 4,2, 29384, 1298]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f7ef0dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "source",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mds_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__delattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: source"
     ]
    }
   ],
   "source": [
    "ds_test.__delattr__('source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54e9c707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_TF_DATASET_REFS',\n",
       " '__class__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getitems__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_build_local_temp_path',\n",
       " '_check_index_is_initialized',\n",
       " '_data',\n",
       " '_estimate_nbytes',\n",
       " '_fingerprint',\n",
       " '_format_columns',\n",
       " '_format_kwargs',\n",
       " '_format_type',\n",
       " '_generate_tables_from_cache_file',\n",
       " '_generate_tables_from_shards',\n",
       " '_get_cache_file_path',\n",
       " '_get_output_signature',\n",
       " '_getitem',\n",
       " '_indexes',\n",
       " '_indices',\n",
       " '_info',\n",
       " '_map_single',\n",
       " '_new_dataset_with_indices',\n",
       " '_output_all_columns',\n",
       " '_push_parquet_shards_to_hub',\n",
       " '_save_to_disk_single',\n",
       " '_select_contiguous',\n",
       " '_select_with_indices_mapping',\n",
       " '_split',\n",
       " 'add_column',\n",
       " 'add_elasticsearch_index',\n",
       " 'add_faiss_index',\n",
       " 'add_faiss_index_from_external_arrays',\n",
       " 'add_item',\n",
       " 'align_labels_with_mapping',\n",
       " 'builder_name',\n",
       " 'cache_files',\n",
       " 'cast',\n",
       " 'cast_column',\n",
       " 'citation',\n",
       " 'class_encode_column',\n",
       " 'cleanup_cache_files',\n",
       " 'column_names',\n",
       " 'config_name',\n",
       " 'data',\n",
       " 'dataset_size',\n",
       " 'description',\n",
       " 'download_checksums',\n",
       " 'download_size',\n",
       " 'drop_index',\n",
       " 'export',\n",
       " 'features',\n",
       " 'filter',\n",
       " 'flatten',\n",
       " 'flatten_indices',\n",
       " 'format',\n",
       " 'formatted_as',\n",
       " 'from_buffer',\n",
       " 'from_csv',\n",
       " 'from_dict',\n",
       " 'from_file',\n",
       " 'from_generator',\n",
       " 'from_json',\n",
       " 'from_list',\n",
       " 'from_pandas',\n",
       " 'from_parquet',\n",
       " 'from_spark',\n",
       " 'from_sql',\n",
       " 'from_text',\n",
       " 'get_index',\n",
       " 'get_nearest_examples',\n",
       " 'get_nearest_examples_batch',\n",
       " 'homepage',\n",
       " 'info',\n",
       " 'is_index_initialized',\n",
       " 'iter',\n",
       " 'license',\n",
       " 'list_indexes',\n",
       " 'load_elasticsearch_index',\n",
       " 'load_faiss_index',\n",
       " 'load_from_disk',\n",
       " 'map',\n",
       " 'num_columns',\n",
       " 'num_rows',\n",
       " 'prepare_for_task',\n",
       " 'push_to_hub',\n",
       " 'remove_columns',\n",
       " 'rename_column',\n",
       " 'rename_columns',\n",
       " 'reset_format',\n",
       " 'save_faiss_index',\n",
       " 'save_to_disk',\n",
       " 'search',\n",
       " 'search_batch',\n",
       " 'select',\n",
       " 'select_columns',\n",
       " 'set_format',\n",
       " 'set_transform',\n",
       " 'shape',\n",
       " 'shard',\n",
       " 'shuffle',\n",
       " 'size_in_bytes',\n",
       " 'sort',\n",
       " 'split',\n",
       " 'supervised_keys',\n",
       " 'task_templates',\n",
       " 'to_csv',\n",
       " 'to_dict',\n",
       " 'to_iterable_dataset',\n",
       " 'to_json',\n",
       " 'to_list',\n",
       " 'to_pandas',\n",
       " 'to_parquet',\n",
       " 'to_sql',\n",
       " 'to_tf_dataset',\n",
       " 'train_test_split',\n",
       " 'unique',\n",
       " 'version',\n",
       " 'with_format',\n",
       " 'with_transform']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cfe5cf3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'term'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mterm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'term'"
     ]
    }
   ],
   "source": [
    "ds.__getattribute__('term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "470da449",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "train_dataset = TextDataset(\n",
    "        tokenizer=tokenizer,\n",
    "        file_path=\"/home/webs8328/cs182_proj/data/untitled.txt\",\n",
    "        block_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a68ff7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.data.datasets.language_modeling.TextDataset object at 0x7fa2c9742760>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cf8e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/webs8328/.local/lib/python3.8/site-packages/peft/tuners/lora/model.py:302: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n",
      "/home/webs8328/.local/lib/python3.8/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2672' max='2672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2672/2672 13:59, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.764600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.217200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.171600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.129500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.106100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fine_tune_gpt2(\"gpt2\", \"/home/webs8328/cs182_proj/data/train_text.txt\", \"test_output2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f37a9782",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', GPT2Model(\n",
      "  (wte): Embedding(50257, 768)\n",
      "  (wpe): Embedding(1024, 768)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      "  (h): ModuleList(\n",
      "    (0-11): 12 x GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (act): NewGELUActivation()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "))\n",
      "('wte', Embedding(50257, 768))\n",
      "('wpe', Embedding(1024, 768))\n",
      "('drop', Dropout(p=0.1, inplace=False))\n",
      "('h', ModuleList(\n",
      "  (0-11): 12 x GPT2Block(\n",
      "    (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (attn): GPT2Attention(\n",
      "      (c_attn): Conv1D()\n",
      "      (c_proj): Conv1D()\n",
      "      (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): GPT2MLP(\n",
      "      (c_fc): Conv1D()\n",
      "      (c_proj): Conv1D()\n",
      "      (act): NewGELUActivation()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "))\n",
      "('h.0', GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('h.0.ln_1', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.0.attn', GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.0.attn.c_attn', Conv1D())\n",
      "('h.0.attn.c_proj', Conv1D())\n",
      "('h.0.attn.attn_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.0.attn.resid_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.0.ln_2', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.0.mlp', GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.0.mlp.c_fc', Conv1D())\n",
      "('h.0.mlp.c_proj', Conv1D())\n",
      "('h.0.mlp.act', NewGELUActivation())\n",
      "('h.0.mlp.dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.1', GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('h.1.ln_1', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.1.attn', GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.1.attn.c_attn', Conv1D())\n",
      "('h.1.attn.c_proj', Conv1D())\n",
      "('h.1.attn.attn_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.1.attn.resid_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.1.ln_2', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.1.mlp', GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.1.mlp.c_fc', Conv1D())\n",
      "('h.1.mlp.c_proj', Conv1D())\n",
      "('h.1.mlp.act', NewGELUActivation())\n",
      "('h.1.mlp.dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.2', GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('h.2.ln_1', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.2.attn', GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.2.attn.c_attn', Conv1D())\n",
      "('h.2.attn.c_proj', Conv1D())\n",
      "('h.2.attn.attn_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.2.attn.resid_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.2.ln_2', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.2.mlp', GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.2.mlp.c_fc', Conv1D())\n",
      "('h.2.mlp.c_proj', Conv1D())\n",
      "('h.2.mlp.act', NewGELUActivation())\n",
      "('h.2.mlp.dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.3', GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('h.3.ln_1', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.3.attn', GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.3.attn.c_attn', Conv1D())\n",
      "('h.3.attn.c_proj', Conv1D())\n",
      "('h.3.attn.attn_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.3.attn.resid_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.3.ln_2', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.3.mlp', GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.3.mlp.c_fc', Conv1D())\n",
      "('h.3.mlp.c_proj', Conv1D())\n",
      "('h.3.mlp.act', NewGELUActivation())\n",
      "('h.3.mlp.dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.4', GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('h.4.ln_1', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.4.attn', GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.4.attn.c_attn', Conv1D())\n",
      "('h.4.attn.c_proj', Conv1D())\n",
      "('h.4.attn.attn_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.4.attn.resid_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.4.ln_2', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.4.mlp', GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.4.mlp.c_fc', Conv1D())\n",
      "('h.4.mlp.c_proj', Conv1D())\n",
      "('h.4.mlp.act', NewGELUActivation())\n",
      "('h.4.mlp.dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.5', GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('h.5.ln_1', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.5.attn', GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.5.attn.c_attn', Conv1D())\n",
      "('h.5.attn.c_proj', Conv1D())\n",
      "('h.5.attn.attn_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.5.attn.resid_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.5.ln_2', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.5.mlp', GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.5.mlp.c_fc', Conv1D())\n",
      "('h.5.mlp.c_proj', Conv1D())\n",
      "('h.5.mlp.act', NewGELUActivation())\n",
      "('h.5.mlp.dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.6', GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('h.6.ln_1', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.6.attn', GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.6.attn.c_attn', Conv1D())\n",
      "('h.6.attn.c_proj', Conv1D())\n",
      "('h.6.attn.attn_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.6.attn.resid_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.6.ln_2', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.6.mlp', GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.6.mlp.c_fc', Conv1D())\n",
      "('h.6.mlp.c_proj', Conv1D())\n",
      "('h.6.mlp.act', NewGELUActivation())\n",
      "('h.6.mlp.dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.7', GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('h.7.ln_1', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.7.attn', GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.7.attn.c_attn', Conv1D())\n",
      "('h.7.attn.c_proj', Conv1D())\n",
      "('h.7.attn.attn_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.7.attn.resid_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.7.ln_2', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.7.mlp', GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.7.mlp.c_fc', Conv1D())\n",
      "('h.7.mlp.c_proj', Conv1D())\n",
      "('h.7.mlp.act', NewGELUActivation())\n",
      "('h.7.mlp.dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.8', GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('h.8.ln_1', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.8.attn', GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.8.attn.c_attn', Conv1D())\n",
      "('h.8.attn.c_proj', Conv1D())\n",
      "('h.8.attn.attn_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.8.attn.resid_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.8.ln_2', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.8.mlp', GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.8.mlp.c_fc', Conv1D())\n",
      "('h.8.mlp.c_proj', Conv1D())\n",
      "('h.8.mlp.act', NewGELUActivation())\n",
      "('h.8.mlp.dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.9', GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('h.9.ln_1', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.9.attn', GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.9.attn.c_attn', Conv1D())\n",
      "('h.9.attn.c_proj', Conv1D())\n",
      "('h.9.attn.attn_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.9.attn.resid_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.9.ln_2', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.9.mlp', GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.9.mlp.c_fc', Conv1D())\n",
      "('h.9.mlp.c_proj', Conv1D())\n",
      "('h.9.mlp.act', NewGELUActivation())\n",
      "('h.9.mlp.dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.10', GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('h.10.ln_1', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.10.attn', GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.10.attn.c_attn', Conv1D())\n",
      "('h.10.attn.c_proj', Conv1D())\n",
      "('h.10.attn.attn_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.10.attn.resid_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.10.ln_2', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.10.mlp', GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.10.mlp.c_fc', Conv1D())\n",
      "('h.10.mlp.c_proj', Conv1D())\n",
      "('h.10.mlp.act', NewGELUActivation())\n",
      "('h.10.mlp.dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.11', GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "))\n",
      "('h.11.ln_1', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.11.attn', GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.11.attn.c_attn', Conv1D())\n",
      "('h.11.attn.c_proj', Conv1D())\n",
      "('h.11.attn.attn_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.11.attn.resid_dropout', Dropout(p=0.1, inplace=False))\n",
      "('h.11.ln_2', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n",
      "('h.11.mlp', GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "))\n",
      "('h.11.mlp.c_fc', Conv1D())\n",
      "('h.11.mlp.c_proj', Conv1D())\n",
      "('h.11.mlp.act', NewGELUActivation())\n",
      "('h.11.mlp.dropout', Dropout(p=0.1, inplace=False))\n",
      "('ln_f', LayerNorm((768,), eps=1e-05, elementwise_affine=True))\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Model\n",
    "\n",
    "model = GPT2Model.from_pretrained(\"gpt2\")\n",
    "for i in model.named_modules():\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90ccd169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7688fd571a104964b7b6ea3bf3e07b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 1024)\n",
      "    (wpe): Embedding(1024, 1024)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-23): 24 x GPT2Block(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a7835f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
